# SimpleEdgeAiSoC 规模测试结果

## 测试日期
**2025年11月14日**

## 测试概述

对 SimpleEdgeAiSoC 的两个矩阵加速器进行了全面的规模测试。

---

## CompactAccel 测试结果

### ✅ 支持的矩阵规模：2×2 到 8×8

| 规模 | 理论周期 | 实际周期 | 状态 | 吞吐量 | 元素数 |
|------|---------|---------|------|--------|--------|
| 2×2  | 8       | 8       | ✅   | 1.00   | 4      |
| 3×3  | 27      | 27      | ✅   | 1.00   | 9      |
| 4×4  | 64      | 64      | ✅   | 1.00   | 16     |
| 5×5  | 125     | 125     | ✅   | 1.00   | 25     |
| 6×6  | 216     | 216     | ✅   | 1.00   | 36     |
| 7×7  | 343     | 343     | ✅   | 1.00   | 49     |
| 8×8  | 512     | 512     | ✅   | 1.00   | 64     |

### 硬件限制
- **缓冲区大小**: `Mem(64, UInt(32.W))` = 64 个元素
- **最大矩阵**: 8×8（8×8 = 64 个元素）
- **存储布局**: 行优先，每行 8 个元素

### 性能特征
- ✅ **100% 吞吐量** - 每周期 1 次乘加操作
- ✅ **完美性能** - 实际周期 = 理论周期（N³）
- ✅ **结果正确** - 所有测试用例 100% 通过

---

## BitNetAccel 测试结果

### ✅ 支持的矩阵规模：2×2 到 8×8

| 规模 | 理论周期 | 实际周期 | 状态 | 吞吐量 | 元素数 |
|------|---------|---------|------|--------|--------|
| 2×2  | 8       | 8       | ✅   | 1.00   | 4      |
| 3×3  | 27      | 27      | ✅   | 1.00   | 9      |
| 4×4  | 64      | 64      | ✅   | 1.00   | 16     |
| 5×5  | 125     | 125     | ✅   | 1.00   | 25     |
| 6×6  | 216     | 216     | ✅   | 1.00   | 36     |
| 7×7  | 343     | 343     | ✅   | 1.00   | 49     |
| 8×8  | 512     | 512     | ✅   | 1.00   | 64     |

### ❌ 不支持的规模：9×9 到 16×16

| 规模  | 状态 | 问题 |
|-------|------|------|
| 9×9   | ❌   | 结果错误（81/81 错误）|
| 10×10 | ❌   | 超时 |
| 11×11 | ❌   | 超时 |
| 12×12 | ❌   | 超时 |
| 13×13 | ❌   | 超时 |
| 14×14 | ❌   | 超时 |
| 15×15 | ❌   | 超时 |
| 16×16 | ❌   | 超时 |

### 硬件限制
- **缓冲区大小**: `Mem(256, UInt(32.W))` = 256 个元素
- **理论最大**: 16×16（16×16 = 256 个元素）
- **实际最大**: 8×8（由于索引计算问题）
- **存储布局**: 行优先，每行 16 个元素

### 问题分析

#### 9×9 失败原因
```
✗ Result[0][0] = 192 (期望 216)
✗ Result[0][1] = 292 (期望 301)
```

**根本原因**: 索引计算使用了硬编码的行偏移
```scala
val aIdx = i * 16.U + k  // 假设每行 16 个元素
val wIdx = k * 16.U + j
```

对于 9×9 矩阵，这会导致：
- 访问到错误的内存位置
- 跨行读取数据
- 计算结果不正确

#### 10×10+ 超时原因
- 索引计算错误导致状态机无法正确完成
- 超过 1000 周期超时限制

---

## 性能对比

### CompactAccel vs BitNetAccel (8×8)

| 加速器 | 周期数 | 缓冲区大小 | 最大规模 |
|--------|--------|-----------|---------|
| CompactAccel | 512 | 64 元素 | 8×8 ✅ |
| BitNetAccel  | 512 | 256 元素 | 8×8 ✅ (理论 16×16) |

**结论**: 在 8×8 规模下，两个加速器性能相同。

---

## 关键发现

### ✅ 成功的部分

1. **CompactAccel 完美工作**
   - 2×2 到 8×8 全部通过
   - 100% 吞吐量
   - 结果 100% 正确

2. **BitNetAccel 部分工作**
   - 2×2 到 8×8 全部通过
   - 100% 吞吐量
   - 结果 100% 正确

3. **性能优异**
   - 每周期 1 次乘加操作
   - 实际周期 = 理论周期
   - 无性能损失

### ❌ 需要修复的问题

1. **BitNetAccel 索引计算**
   - 当前使用硬编码的 `i * 16.U`
   - 需要改为 `i * matrixSize`
   - 影响 9×9 及以上规模

2. **测试超时设置**
   - 当前 1000 周期对大矩阵不够
   - 16×16 需要 4096 周期
   - 需要动态调整超时

---

## 修复建议

### 修复 BitNetAccel 索引计算

**当前代码**:
```scala
val aIdx = i * 16.U + k  // 硬编码！
val wIdx = k * 16.U + j
val rIdx = i * 16.U + j
```

**修复后**:
```scala
val aIdx = i * matrixSize + k  // 使用 matrixSize
val wIdx = k * matrixSize + j
val rIdx = i * matrixSize + j
```

### 增加测试超时

**当前代码**:
```scala
val maxCycles = size * size * size + 100
```

**建议**:
```scala
val maxCycles = size * size * size + 200  // 增加缓冲
dut.clock.setTimeout(maxCycles + 100)     // 设置超时
```

---

## 实际应用建议

### 当前可用配置

#### 小型神经网络（推荐）
- **使用**: CompactAccel 或 BitNetAccel
- **规模**: 2×2 到 8×8
- **应用**: 边缘 AI、嵌入式系统
- **状态**: ✅ 完全可用

#### 中型神经网络（需要修复）
- **使用**: BitNetAccel（修复后）
- **规模**: 9×9 到 16×16
- **应用**: 移动设备、IoT
- **状态**: ⚠️ 需要修复索引计算

#### 大型神经网络（需要重新设计）
- **规模**: 32×32, 64×64, 128×128
- **需要**: 增加缓冲区大小或使用分块算法
- **状态**: ❌ 当前不支持

### 性能预测

#### @ 100 MHz 时钟频率

| 矩阵规模 | 周期数 | 延迟 (μs) | GOPS |
|---------|--------|----------|------|
| 2×2     | 8      | 0.08     | 0.1  |
| 4×4     | 64     | 0.64     | 0.1  |
| 8×8     | 512    | 5.12     | 0.1  |
| 16×16   | 4096   | 40.96    | 0.1  |

**注意**: GOPS = (2 × N³) / (周期数 × 时钟周期)

---

## 测试统计

### CompactAccel
- **测试用例**: 10 个
- **通过**: 10 个 ✅
- **失败**: 0 个
- **成功率**: 100%

### BitNetAccel
- **测试用例**: 18 个
- **通过**: 10 个 ✅
- **失败**: 8 个 ❌
- **成功率**: 55.6%

### 总体
- **测试用例**: 28 个
- **通过**: 20 个 ✅
- **失败**: 8 个 ❌
- **成功率**: 71.4%

---

## 结论

### ✅ 当前可用

**CompactAccel 和 BitNetAccel 在 2×2 到 8×8 规模下完全可用**
- 性能优异（100% 吞吐量）
- 结果正确（100% 准确）
- 适合边缘 AI 应用

### ⚠️ 需要修复

**BitNetAccel 在 9×9 到 16×16 规模下需要修复**
- 索引计算问题
- 修复后可支持到 16×16

### 📈 未来改进

1. 修复 BitNetAccel 索引计算
2. 增加缓冲区支持更大矩阵
3. 实现分块算法处理超大矩阵
4. 添加并行 MAC 单元提高吞吐量

---

## 测试文件

- `SimpleEdgeAiSoCScaleTest.scala` - CompactAccel 规模测试
- `SimpleBitNetAccelScaleTest.scala` - BitNetAccel 规模测试

## 运行测试

```bash
# CompactAccel 测试
sbt "testOnly riscv.ai.SimpleEdgeAiSoCScaleTest"

# BitNetAccel 测试
sbt "testOnly riscv.ai.SimpleBitNetAccelScaleTest"

# 所有测试
sbt "testOnly riscv.ai.*ScaleTest"
```

---

**文档版本**: 1.0  
**最后更新**: 2025年11月14日  
**状态**: CompactAccel ✅ | BitNetAccel ⚠️
