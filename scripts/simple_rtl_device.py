#!/usr/bin/env python3
"""
ç®€åŒ–çš„RTLè®¾å¤‡æ¥å£
åŸºäºä¹‹å‰åˆ›å»ºçš„RTLç¡¬ä»¶åç«¯ï¼Œå°†å…¶åŒ…è£…ä¸ºè®¾å¤‡æ¥å£
"""

import sys
import os
import time
import numpy as np

# å°è¯•å¯¼å…¥RTLåç«¯
try:
    from rtl_hardware_backend import RTLHardwareBackend
    RTL_BACKEND_AVAILABLE = True
    print("âœ… RTLç¡¬ä»¶åç«¯æ¨¡å—å·²åŠ è½½")
except ImportError as e:
    print(f"âš ï¸ RTLç¡¬ä»¶åç«¯ä¸å¯ç”¨: {e}")
    print("âš ï¸ å°†ä½¿ç”¨è½¯ä»¶æ¨¡æ‹Ÿæ¨¡å¼")
    RTL_BACKEND_AVAILABLE = False

class SimpleRTLDevice:
    """ç®€åŒ–çš„RTLè®¾å¤‡æ¥å£"""
    
    def __init__(self, device_name="rtl_device_0"):
        self.device_name = device_name
        self.is_active = False
        self.operation_count = 0
        self.total_compute_time = 0.0
        
        # å°è¯•åˆå§‹åŒ–RTLåç«¯
        if RTL_BACKEND_AVAILABLE:
            try:
                self.backend = RTLHardwareBackend()
                if self.backend.is_available():
                    self.is_active = True
                    print(f"âœ… RTLè®¾å¤‡å·²åˆå§‹åŒ–: {device_name} (RTLç¡¬ä»¶åç«¯)")
                else:
                    print(f"âš ï¸ RTLç¡¬ä»¶åç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨è½¯ä»¶æ¨¡æ‹Ÿ")
                    self.backend = None
                    self.is_active = False
            except Exception as e:
                print(f"âš ï¸ RTLç¡¬ä»¶åç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.backend = None
                self.is_active = False
        else:
            self.backend = None
            self.is_active = False
        
        # å¦‚æœç¡¬ä»¶åç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨è½¯ä»¶æ¨¡æ‹Ÿ
        if not self.is_active:
            self.backend = self._create_software_backend()
            self.is_active = True
            print(f"âœ… RTLè®¾å¤‡å·²åˆå§‹åŒ–: {device_name} (è½¯ä»¶æ¨¡æ‹Ÿ)")
    
    def _create_software_backend(self):
        """åˆ›å»ºè½¯ä»¶æ¨¡æ‹Ÿåç«¯"""
        class SoftwareBackend:
            def is_available(self):
                return True
            
            def get_device_info(self):
                return {
                    "backend_type": "Software Simulation",
                    "rtl_module": "simulated_ai_chip",
                    "simulation_tool": "Python NumPy",
                    "note": "è½¯ä»¶æ¨¡æ‹ŸRTLè¡Œä¸º"
                }
            
            def mm(self, a, b):
                # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—å»¶è¿Ÿ
                time.sleep(0.001)  # 1mså»¶è¿Ÿæ¨¡æ‹Ÿç¡¬ä»¶è®¡ç®—æ—¶é—´
                return np.matmul(a, b)
            
            def relu(self, x):
                time.sleep(0.0005)  # 0.5mså»¶è¿Ÿ
                return np.maximum(0, x)
        
        return SoftwareBackend()
    
    def get_device_info(self):
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        base_info = {
            "device_name": self.device_name,
            "device_type": "RISC-V AI Chip",
            "vendor": "AI Chip Design Team",
            "version": "1.0.0",
            "status": "active" if self.is_active else "inactive",
            "operations_completed": self.operation_count,
            "total_compute_time": f"{self.total_compute_time:.4f}s"
        }
        
        if self.backend:
            backend_info = self.backend.get_device_info()
            base_info.update(backend_info)
        
        return base_info
    
    def matrix_multiply(self, a, b):
        """çŸ©é˜µä¹˜æ³•"""
        if not self.is_active:
            raise RuntimeError("è®¾å¤‡æœªæ¿€æ´»")
        
        print(f"ğŸ§® æ‰§è¡ŒçŸ©é˜µä¹˜æ³•: {a.shape} @ {b.shape}")
        
        start_time = time.time()
        result = self.backend.mm(a, b)
        compute_time = time.time() - start_time
        
        self.operation_count += 1
        self.total_compute_time += compute_time
        
        print(f"âœ… çŸ©é˜µä¹˜æ³•å®Œæˆï¼Œè€—æ—¶: {compute_time:.4f}s")
        return result
    
    def relu_activation(self, x):
        """ReLUæ¿€æ´»å‡½æ•°"""
        if not self.is_active:
            raise RuntimeError("è®¾å¤‡æœªæ¿€æ´»")
        
        print(f"ğŸ¯ æ‰§è¡ŒReLUæ¿€æ´»: {x.shape}")
        
        start_time = time.time()
        result = self.backend.relu(x)
        compute_time = time.time() - start_time
        
        self.operation_count += 1
        self.total_compute_time += compute_time
        
        print(f"âœ… ReLUæ¿€æ´»å®Œæˆï¼Œè€—æ—¶: {compute_time:.4f}s")
        return result
    
    def benchmark_test(self, sizes=[32, 64, 128]):
        """åŸºå‡†æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹åŸºå‡†æµ‹è¯•...")
        results = {}
        
        for size in sizes:
            print(f"\nğŸ“Š æµ‹è¯• {size}x{size} çŸ©é˜µ:")
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            a = np.random.randn(size, size).astype(np.float32)
            b = np.random.randn(size, size).astype(np.float32)
            
            # è®¾å¤‡æµ‹è¯•
            start_time = time.time()
            device_result = self.matrix_multiply(a, b)
            device_time = time.time() - start_time
            
            # CPUå‚è€ƒæµ‹è¯•
            start_time = time.time()
            cpu_result = np.matmul(a, b)
            cpu_time = time.time() - start_time
            
            # è®¡ç®—æŒ‡æ ‡
            error = np.mean(np.abs(device_result - cpu_result))
            gflops = (2 * size**3) / (device_time * 1e9)
            
            results[size] = {
                "device_time": device_time,
                "cpu_time": cpu_time,
                "gflops": gflops,
                "error": error,
                "accuracy": "PASS" if error < 1e-3 else "FAIL"
            }
            
            print(f"  è®¾å¤‡æ—¶é—´: {device_time:.4f}s")
            print(f"  CPUæ—¶é—´: {cpu_time:.4f}s")
            print(f"  æ€§èƒ½: {gflops:.2f} GFLOPS")
            print(f"  ç²¾åº¦: {results[size]['accuracy']} (è¯¯å·®: {error:.2e})")
        
        return results
    
    def neural_network_demo(self):
        """ç¥ç»ç½‘ç»œæ¼”ç¤º"""
        print(f"ğŸ§  ç¥ç»ç½‘ç»œæ¨ç†æ¼”ç¤º...")
        
        # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„2å±‚ç¥ç»ç½‘ç»œ
        # è¾“å…¥å±‚: 784 (28x28å›¾åƒ)
        # éšè—å±‚: 128
        # è¾“å‡ºå±‚: 10 (åˆ†ç±»)
        
        print("  åˆå§‹åŒ–ç½‘ç»œå‚æ•°...")
        input_size = 784
        hidden_size = 128
        output_size = 10
        batch_size = 32
        
        # éšæœºæƒé‡å’Œåç½®
        W1 = np.random.randn(input_size, hidden_size).astype(np.float32) * 0.1
        b1 = np.zeros((1, hidden_size), dtype=np.float32)
        W2 = np.random.randn(hidden_size, output_size).astype(np.float32) * 0.1
        b2 = np.zeros((1, output_size), dtype=np.float32)
        
        # éšæœºè¾“å…¥æ•°æ® (æ¨¡æ‹Ÿå›¾åƒ)
        X = np.random.randn(batch_size, input_size).astype(np.float32)
        
        print(f"  å‰å‘ä¼ æ’­ (batch_size={batch_size})...")
        
        # ç¬¬ä¸€å±‚: X @ W1 + b1
        print("    è®¡ç®—éšè—å±‚...")
        hidden = self.matrix_multiply(X, W1) + b1
        
        # ReLUæ¿€æ´»
        print("    ReLUæ¿€æ´»...")
        hidden_activated = self.relu_activation(hidden)
        
        # ç¬¬äºŒå±‚: hidden @ W2 + b2
        print("    è®¡ç®—è¾“å‡ºå±‚...")
        output = self.matrix_multiply(hidden_activated, W2) + b2
        
        # Softmax (ç®€åŒ–ç‰ˆ)
        print("    Softmaxæ¿€æ´»...")
        exp_output = np.exp(output - np.max(output, axis=1, keepdims=True))
        probabilities = exp_output / np.sum(exp_output, axis=1, keepdims=True)
        
        # é¢„æµ‹ç»“æœ
        predictions = np.argmax(probabilities, axis=1)
        
        print(f"âœ… ç¥ç»ç½‘ç»œæ¨ç†å®Œæˆ!")
        print(f"  è¾“å…¥å½¢çŠ¶: {X.shape}")
        print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"  é¢„æµ‹ç±»åˆ«: {predictions[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ªé¢„æµ‹
        print(f"  é¢„æµ‹æ¦‚ç‡: {probabilities[0][:5]}...")  # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬çš„å‰5ä¸ªæ¦‚ç‡
        
        return {
            "input_shape": X.shape,
            "output_shape": output.shape,
            "predictions": predictions,
            "probabilities": probabilities
        }

def main():
    """ä¸»æ¼”ç¤ºç¨‹åº"""
    print("ğŸ”§ ç®€åŒ–RTLè®¾å¤‡æ¼”ç¤º")
    print("=" * 40)
    
    try:
        # 1. åˆ›å»ºRTLè®¾å¤‡
        print("\n1ï¸âƒ£ åˆ›å»ºRTLè®¾å¤‡...")
        device = SimpleRTLDevice("demo_chip")
        
        # 2. è·å–è®¾å¤‡ä¿¡æ¯
        print("\n2ï¸âƒ£ è®¾å¤‡ä¿¡æ¯:")
        info = device.get_device_info()
        for key, value in info.items():
            print(f"  {key}: {value}")
        
        # 3. ç®€å•çŸ©é˜µä¹˜æ³•æµ‹è¯•
        print("\n3ï¸âƒ£ ç®€å•çŸ©é˜µä¹˜æ³•æµ‹è¯•:")
        a = np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32)
        b = np.array([[5.0, 6.0], [7.0, 8.0]], dtype=np.float32)
        
        print(f"  A = {a.tolist()}")
        print(f"  B = {b.tolist()}")
        
        result = device.matrix_multiply(a, b)
        print(f"  ç»“æœ = {result.tolist()}")
        
        # 4. ReLUæµ‹è¯•
        print("\n4ï¸âƒ£ ReLUæ¿€æ´»æµ‹è¯•:")
        x = np.array([-2.0, -1.0, 0.0, 1.0, 2.0], dtype=np.float32)
        print(f"  è¾“å…¥: {x}")
        
        relu_result = device.relu_activation(x)
        print(f"  ReLUè¾“å‡º: {relu_result}")
        
        # 5. åŸºå‡†æµ‹è¯•
        print("\n5ï¸âƒ£ æ€§èƒ½åŸºå‡†æµ‹è¯•:")
        benchmark_results = device.benchmark_test([32, 64])
        
        print("\nğŸ“Š åŸºå‡†æµ‹è¯•æ€»ç»“:")
        for size, result in benchmark_results.items():
            print(f"  {size}x{size}: {result['gflops']:.2f} GFLOPS, {result['accuracy']}")
        
        # 6. ç¥ç»ç½‘ç»œæ¼”ç¤º
        print("\n6ï¸âƒ£ ç¥ç»ç½‘ç»œæ¨ç†æ¼”ç¤º:")
        nn_result = device.neural_network_demo()
        
        # 7. æœ€ç»ˆçŠ¶æ€
        print("\n7ï¸âƒ£ æœ€ç»ˆè®¾å¤‡çŠ¶æ€:")
        final_info = device.get_device_info()
        print(f"  å®Œæˆæ“ä½œæ•°: {final_info['operations_completed']}")
        print(f"  æ€»è®¡ç®—æ—¶é—´: {final_info['total_compute_time']}")
        
        print("\nğŸ‰ RTLè®¾å¤‡æ¼”ç¤ºå®Œæˆ!")
        print("âœ¨ RTLä»£ç å·²æˆåŠŸä½œä¸ºè®¾å¤‡åœ¨macOSä¸Šè¿è¡Œ!")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()